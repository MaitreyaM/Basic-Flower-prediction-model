{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyqD+z2LAGCo7eVzBne/L2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaitreyaM/Basic-Flower-prediction-model/blob/main/Sentimentdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9g75cB86pdl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk scikit-learn\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import warnings\n"
      ],
      "metadata": {
        "id": "06BsWZID9LS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f7d266-1d32-4347-da1c-9d463a93e22f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqU54bPpUhLR",
        "outputId": "97be7233-4e4a-4e47-f180-187077f7fcba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable NLTK warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Ijr5K5SNUqmR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset\n",
        "data = [\n",
        "    (\"I love this product!\", \"positive\"),\n",
        "    (\"This is terrible.\", \"negative\"),\n",
        "    (\"I'm not sure.\", \"neutral\"),\n",
        "    (\"It's amazing!\", \"positive\"),\n",
        "    (\"I don't like it.\", \"negative\"),\n",
        "]\n"
      ],
      "metadata": {
        "id": "G5NluCuaUvUB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "texts, labels = zip(*data)\n",
        "\n",
        "cleaned_texts = []\n",
        "for text in texts:\n",
        "    tokens = word_tokenize(text)\n",
        "    cleaned_tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
        "    cleaned_texts.append(\" \".join(cleaned_tokens))\n"
      ],
      "metadata": {
        "id": "VrXZIHcgVPS6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(cleaned_texts, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Y2W2x2VEVTJp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "uNMyF42VVVTK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict sentiment on test data\n",
        "y_pred = classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Sentiment Analysis using NLTK's VADER\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def analyze_sentiment(sentence):\n",
        "    sentiment = analyzer.polarity_scores(sentence)\n",
        "    if sentiment['compound'] >= 0.05:\n",
        "        return \"positive\"\n",
        "    elif sentiment['compound'] <= -0.05:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvOlL7EUVXtx",
        "outputId": "dfdfee73-2c72-4917-c039-b6e8fe275a73"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    # Analyze sentiment using VADER\n",
        "    sentiment = analyze_sentiment(user_input)\n",
        "    print(f\"Bot: You sound {sentiment}!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-iHVAF0VcwB",
        "outputId": "ca8d9ba4-8386-49fb-c417-0ace77d544df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: Horrendous\n",
            "Bot: You sound negative!\n",
            "You: its alright\n",
            "Bot: You sound positive!\n",
            "You: ehh lame\n",
            "Bot: You sound negative!\n",
            "You: Exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our chat bot is ready. It can analyze statements using both NaÃ¯ve Bayes classifier\n",
        "And NLTK vader sentiment analysis tool;\n",
        "Project. You can type your messages, and the chatbot will respond with the sentiment it detects. To exit the chat, type \"exit.\"\n"
      ],
      "metadata": {
        "id": "ppb61eI0WGAn"
      }
    }
  ]
}